{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import TensorDataset\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import cv2 \n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import json\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from utils import * \n",
    "import math\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHARS = [\n",
    "         '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
    "         'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K',\n",
    "         'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V',\n",
    "         'W', 'X', 'Y', 'Z', 'I', 'O', '-'\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the network with 6 stages\n",
    "CPMmodel = CPMLicensePlateNet(num_stages=6)\n",
    "CPMmodel.load_state_dict(torch.load(\"./cpmweight_11.pth\"))\n",
    "CPMmodel.to('cuda').eval()\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 100, 100])\n",
      "[(7, 28), (94, 36), (94, 76), (8, 69)]\n"
     ]
    }
   ],
   "source": [
    "test_img = cv2.imread(\"./761TJL.jpg\")\n",
    "\n",
    "\n",
    "# test_img_pil = Image.fromarray(test_img)\n",
    "# test_img_pil.show()\n",
    "\n",
    "test_img_resize = cv2.resize(test_img,(100,100))\n",
    "original_img = test_img_resize.copy()\n",
    "\n",
    "img = original_img/255.0\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img = torch.from_numpy(img).float()\n",
    "img = img.permute(0, 3, 1, 2)\n",
    "img = img.to('cuda:0')\n",
    "print(img.shape)\n",
    "s1_g1_out,  s2_g2_out,  s3_g2_out,  s4_g2_out,  s5_g2_out,  s6_g2_out,  s7_g2_out2 = CPMmodel(img)\n",
    "\n",
    "output_heatmap = s7_g2_out2[0]\n",
    "\n",
    "output_heatmap = output_heatmap.unsqueeze(0)  # x的形状变为[1, 4, 50, 50]\n",
    "output_heatmap = F.interpolate(output_heatmap, size=(100, 100), mode='bilinear', align_corners=False)\n",
    "output_heatmap = output_heatmap.squeeze(0)  # 移除增加的维度，形状变回[4, 100, 100]\n",
    "confirm_point=[]\n",
    "for i in range(4):\n",
    "    y=np.argmax(output_heatmap[i].to('cpu').detach().numpy())//100\n",
    "    x=np.argmax(output_heatmap[i].to('cpu').detach().numpy())%100\n",
    "    confirm_point.append((x,y))\n",
    "print(confirm_point)\n",
    "\n",
    "# # 定義原始點的列表\n",
    "# points = confirm_point\n",
    "\n",
    "# # 計算中心點\n",
    "# center_x = sum(x for x, y in points) / len(points)\n",
    "# center_y = sum(y for x, y in points) / len(points)\n",
    "\n",
    "# # 計算擴大後的點\n",
    "# scaled_points = []\n",
    "# for x, y in points:\n",
    "#     scaled_x = center_x + (x - center_x) * 1.0\n",
    "#     scaled_y = center_y + (y - center_y) * 1.2\n",
    "#     scaled_points.append((scaled_x, scaled_y))\n",
    "# print(scaled_points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#假设 cropped_image_2 已经是一个加载的图像\n",
    "image = test_img_resize.copy()\n",
    "#使用 confirm_point 作为原始点坐标\n",
    "pts1 = np.float32(confirm_point)\n",
    "# 目标点坐标\n",
    "pts2 = np.float32([[0, 0], [100, 0], [100, 50], [0, 50]])\n",
    "\n",
    "# 计算透视变换矩阵\n",
    "matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "\n",
    "# 应用透视变换\n",
    "CPM_result = cv2.warpPerspective(image, matrix, (100, 50))\n",
    "CPM_result = cv2.resize(CPM_result,(94,48))\n",
    "\n",
    "# cv2.imwrite('rotated_BBN613.jpg',CPM_result)\n",
    "# img_pil = Image.fromarray(CPM_result)\n",
    "# img_pil.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful to build network!\n"
     ]
    }
   ],
   "source": [
    "from data.load_data import CHARS, CHARS_DICT, LPRDataLoader\n",
    "import time\n",
    "\n",
    "#LPRmodel = build_lprnet(lpr_max_len=8, phase=False, class_num=len(CHARS), dropout_rate=0)\n",
    "LPRmodel = LPRNet(lpr_max_len=7, phase=False, class_num=len(CHARS), dropout_rate=0.5)\n",
    "LPRmodel.load_state_dict(torch.load(\"./LPRaddbatch/best_ACC_iteration_70299.pth\"))\n",
    "\n",
    "LPRmodel.to(\"cuda\")\n",
    "print(\"Successful to build network!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict:  761TJL\n"
     ]
    }
   ],
   "source": [
    "# 首先，添加一个批量维度\n",
    "\n",
    "# CPM_result = CPM_result.astype('float32')\n",
    "# CPM_result -= 127.5\n",
    "# CPM_result *= 0.0078125\n",
    "# CPM_result = np.transpose(CPM_result, (2, 0, 1))\n",
    "\n",
    "\n",
    "# CPM_result_tensor = torch.from_numpy(CPM_result)\n",
    "# CPM_result_tensor_with_batch = CPM_result_tensor.unsqueeze(0)\n",
    "# CPM_result_to_model = CPM_result_tensor_with_batch.to(\"cuda\")\n",
    "# print(CPM_result_to_model.shape)\n",
    "# prebs = LPRmodel(CPM_result_to_model)\n",
    "\n",
    "\n",
    "\n",
    "# # greedy decode\n",
    "# prebs = prebs.cpu().detach().numpy()\n",
    "# preb_labels = list()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Image = cv2.imread(\"./img/BBN6136.jpg\")\n",
    "Image = CPM_result\n",
    "\n",
    "Image = Image.astype('float32')\n",
    "Image -= 127.5\n",
    "Image *= 0.0078125\n",
    "Image = np.transpose(Image, (2, 0, 1))\n",
    "\n",
    "torchimgs = torch.from_numpy(Image)\n",
    "torchimgs = torch.unsqueeze(torchimgs, 0)\n",
    "torchimgs = torchimgs.cuda()\n",
    "\n",
    "# forward\n",
    "LPRmodel.eval()\n",
    "prebs = LPRmodel(torchimgs)\n",
    "# greedy decode\n",
    "prebs = prebs.cpu().detach().numpy()\n",
    "\n",
    "preb = prebs[0]\n",
    "preb_label = []\n",
    "no_repeat_blank_label = []\n",
    "\n",
    "for j in range(18):\n",
    "    preb_label.append(np.argmax(preb[:, j], axis=0))\n",
    "\n",
    "pre_c = preb_label[0]\n",
    "if pre_c != len(CHARS) - 1:\n",
    "    no_repeat_blank_label.append(pre_c)\n",
    "\n",
    "for c in preb_label:\n",
    "    if (pre_c == c) or (c == len(CHARS) - 1):\n",
    "        if c == len(CHARS) - 1:\n",
    "            pre_c = c\n",
    "        continue\n",
    "    no_repeat_blank_label.append(c)\n",
    "    pre_c = c\n",
    "\n",
    "\n",
    "lb = \"\"\n",
    "for i in no_repeat_blank_label:\n",
    "    lb += CHARS[i]\n",
    "\n",
    "print(\"predict: \", lb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
